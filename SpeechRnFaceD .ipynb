{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistive Robotics \n",
    "\n",
    "### Team 4:\n",
    "### Mask Assistance with a Robotic Arm!\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "- !pip install SpeechRecognition\n",
    "- !pip install cv2\n",
    "- !pip install pyaudio\n",
    "- !conda install -c conda-forge dlib   \n",
    "\n",
    "- Download a file from here- https://github.com/AKSHAYUBHAT/TensorFace/blob/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![68 Landmarks](facial_landmarks_68.jpg \"LandMarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def StartVideo():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Window\")\n",
    "    \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('C:/Users/Tejas/Downloads/MS/Sem4/Assistive Robotics/Final Project/shape_predictor_68_face_landmarks.dat')\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        ## Facial detection\n",
    "        faces = detector(gray)\n",
    "        #print(len(faces)) # =1\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1) #1 pixel thickness\n",
    "            \n",
    "            landmarks = predictor(gray, face)\n",
    "            \n",
    "            '''\n",
    "            ### Find the ears upper and lower region\n",
    "            #for n in range(0, 68):\n",
    "            for n in [0, 2, 14, 16]:      ### Ears = [0,2,14,16]\n",
    "                x = landmarks.part(n).x\n",
    "                y = landmarks.part(n).y\n",
    "                cv2.circle(frame, (x,y), 3, (255, 0, 0), -1) #radius=3, fill the circle = -1\n",
    "            '''   \n",
    "        \n",
    "              \n",
    "        ### Drawing a line from point 28 to 8.\n",
    "        x28 = landmarks.part(28).x\n",
    "        y28 = landmarks.part(28).y\n",
    "        x8 = landmarks.part(8).x\n",
    "        y8 = landmarks.part(8).y\n",
    "        \n",
    "        \n",
    "        ### Calculate angle between the 2 points\n",
    "        angle = math.atan2((y8-y28),(x8-x28))*180/3.141592653;\n",
    "        angle = angle + math.ceil(-angle / 360 ) * 360\n",
    "        \n",
    "        allx = []\n",
    "        ally = []\n",
    "        if angle > 85 and angle < 95:\n",
    "            \n",
    "            x = landmarks.part(66).x\n",
    "            y = landmarks.part(66).y\n",
    "            \n",
    "            allx.append(x)\n",
    "            ally.append(y)\n",
    "            \n",
    "            cv2.putText(frame, \"Perfect, stay still!, mouth location = ({},{})\".format(x, y),\n",
    "                    (0,25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "            \n",
    "\n",
    "            cv2.circle(frame, (x,y), 4, (255, 0, 0), -1) #radius=3, fill the circle = -1 \n",
    "            #return x, y\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            ### Facial Center points forehead, lower lip center and chin. Points 28, 57 and 8.\n",
    "            for n in [28, 57, 8]:\n",
    "                x = landmarks.part(n).x\n",
    "                y = landmarks.part(n).y\n",
    "                cv2.circle(frame, (x,y), 4, (255, 0, 0), -1) #radius=3, fill the circle = -1\n",
    "            \n",
    "            \n",
    "            cv2.line(frame, (x28, y28), (x8,y8), (0,0,0), 2) \n",
    "\n",
    "\n",
    "            ### Tell the user to adjust the face orientation\n",
    "            #cv2.putText(img,'Hello World!', bottomLeftCornerOfText, font, fontScale,fontColor,lineType)\n",
    "            cv2.putText(frame,'Adjust face to 90 Deg, current angle = {}'.format(angle),\n",
    "                        (0,25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "                \n",
    "        \n",
    "        cv2.imshow(\"Window\", frame)\n",
    "\n",
    "        #This breaks on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return math.floor(np.mean(allx)), math.floor(np.mean(ally))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = StartVideo()\n",
    "print(\"Mouth Location = ({},{})\".format(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Speaking....\n",
      "Recording Ended!\n",
      "hi hello\n",
      "Mouth Location = (367,314)\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print('Start Speaking....')\n",
    "    audio = r.listen(source, phrase_time_limit=3)\n",
    "    print(\"Recording Ended!\")\n",
    "    \n",
    "try:\n",
    "    text = r.recognize_google(audio)\n",
    "    print(text)\n",
    "except:\n",
    "    print(\"Could Not Understand the audio!, Retry again!\")\n",
    "    \n",
    "    \n",
    "if text == 'hi hello':\n",
    "    x, y = StartVideo()\n",
    "\n",
    "print(\"Mouth Location = ({},{})\".format(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
